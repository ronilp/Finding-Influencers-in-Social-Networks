profit organization miri mission ensure creation smarter human intelligence positive impact machine intelligence research institute ted talk nick bostrom potential superintelligence lies dormant matter power atom lay dormant human history patiently waiting 1945 piece givewell overview eclectic mix effective altruism investigates global catastrophic risks mentioned section plague beginning stuart armstrong slew ai safety ideas sixteen centre study existential risk cambridge recruiting team time postdoctoral research associates investigate technology risks application april 24 5 00 pst throwback thursday paper aaai 2014 workshop multiagent interaction tbt reasons prioritize ai safety research bad reasons final discussion post superintelligence reading update miri activities past month news miri research aimed formally desirable features smarter human ai organizational priority progress technical agenda personally attention devoted picture ai strategy forecasting earmark miri donations fund research ai impacts project forum discussion competition cooperation ai projects organized conclusion bostrom superintelligence